{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import struct\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trans .csv to .param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_csv_to_param():\n",
    "    with open('mynet.param','w') as p: \n",
    "        with open('mynet.csv','r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "\n",
    "            blobs = []\n",
    "            outputcontent = ''\n",
    "            row_index = 0\n",
    "            for row in f_csv:   ## read rows in csv\n",
    "                # normal lines <layertype   layername   inputNum outputNum inputBlob outputBlob params>\n",
    "                col_index = 0\n",
    "                for col in row:\n",
    "                    if col_index == 0:                # layertype\n",
    "                        outputcontent += '%-16s ' % (col)\n",
    "                    elif col_index == 1:              # layername\n",
    "                        outputcontent += '%-32s ' % (col)\n",
    "                    elif col_index == 2:              # inputNum\n",
    "                        inputBlobNum = int(col)\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    elif col_index == 3:              # outputNum\n",
    "                        outputBlobNum = int(col)\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    elif col_index > 3 and col_index <= 3+inputBlobNum+outputBlobNum:  # inputBlob outputBlob\n",
    "                        blobs.append(col)\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    else:                             # params\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    col_index += 1\n",
    "                outputcontent += '\\n'\n",
    "                row_index += 1  ## end of read rows in csv\n",
    "            outputcontent = '7767517\\n'+'%s '%(row_index)+'%s\\n'%(len(list(set(blobs))))+outputcontent\n",
    "            p.write(outputcontent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process conv unit from json to csv\n",
    "# save json buffer data to bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save memorydata [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bin():\n",
    "    a = [1]\n",
    "    with open('mynet.bin','wb') as f:\n",
    "        for i in a:\n",
    "            print(struct.pack('<f',i))\n",
    "            f.write(struct.pack('<f',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = \"/home/gx/myproj/flatbuffers/im14_without_q_att.json\"\n",
    "with open(jsonpath,'r') as f_json:\n",
    "    model = json.load(f_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append new row to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row_to_csv(appendList):\n",
    "    with open('mynet.csv','a', newline = \"\") as f:\n",
    "        csv_writer = csv.writer(f, dialect = \"excel\")\n",
    "        csv_writer.writerow(appendList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save TF-buffer data to NCNN-bin file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM o-h-w-i(tflite) TO o-i-h-w(ncnn)\n",
    "def fix_weight_order(list):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weight & bias data from tflite-json file to ncnn-bin file\n",
    "def save_data_to_bin(bufferIndex, savefilter=True, append=True):\n",
    "    bufferData = model['buffers'][bufferIndex]['data']\n",
    "    flag = 'ab' if append else 'wb'\n",
    "    with open('mynet.bin',flag) as f:\n",
    "        if savefilter:\n",
    "            i = 0x00000000   # flag-structure: weight data need to save as float type\n",
    "            f.write(struct.pack('<I',i))\n",
    "            fix_weight_order(bufferData)\n",
    "        for i in bufferData: # sava bufferdata\n",
    "            f.write(struct.pack('B',i))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save several type of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conv(name, indexTfLite, inputBlob, outputBlob):\n",
    "    \n",
    "    op = model['subgraphs'][0]['operators']\n",
    "    tensor = model['subgraphs'][0]['tensors']\n",
    "    \n",
    "    filterTensor = op[indexTfLite]['inputs'][1]\n",
    "    biasTensor = op[indexTfLite]['inputs'][2]\n",
    "\n",
    "    if 'dilation_w_factor' in op[indexTfLite]['builtin_options'].keys():\n",
    "        dilation_w_factor = op[indexTfLite]['builtin_options']['dilation_w_factor']\n",
    "    else:\n",
    "        dilation_w_factor = '1'\n",
    "        \n",
    "    if 'stride_w' in op[indexTfLite]['builtin_options'].keys():\n",
    "        stride_w = op[indexTfLite]['builtin_options']['stride_w']\n",
    "    else:\n",
    "        stride_w = '1'\n",
    "\n",
    "    param = ['0=' + str(tensor[filterTensor]['shape'][0]), # num_output\n",
    "             '1=' + str(tensor[filterTensor]['shape'][1]), # kernel_w   （kernel_h default）\n",
    "             '2=' + str(dilation_w_factor),                # rate\n",
    "             '3=' + str(stride_w),                         # stride\n",
    "             '4=-233',                                     # same\n",
    "             '5=1',                                        # has bias\n",
    "             '6=' + str(reduce(lambda x,y:x*y,tensor[filterTensor]['shape'])) # weight\n",
    "            ]\n",
    "    \n",
    "    append_row_to_csv(['Convolution']+[name]+['1','1']+[inputBlob,name]+param)\n",
    "    save_data_to_bin(tensor[filterTensor]['buffer'],True)  # save filter's buffer (weight)\n",
    "    save_data_to_bin(tensor[biasTensor]['buffer'],False)   # save bias's   buffer \n",
    "    return outputBlob\n",
    "\n",
    "def save_slice(name, inputBlob, outputBlob1, outputBlob2):\n",
    "    append_row_to_csv(['Slice']+[name]+['1','2']+[inputBlob,outputBlob1,outputBlob2]+['0=-233','1=2'])\n",
    "    return outputBlob1, outputBlob2\n",
    "\n",
    "def save_interp(name, inputBlob, outputBlob):                         # ResizeNearestNeighbor 2*\n",
    "    append_row_to_csv(['Interp']+[name]+['1','1']+[inputBlob,outputBlob]+['0=0','1=2','2=2']) \n",
    "    return outputBlob\n",
    "\n",
    "def save_elu(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['ELU']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "    \n",
    "def save_relu(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['Relu']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "    \n",
    "def save_tanh(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['TanH']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "    \n",
    "def save_sigmoid(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['Sigmoid']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "\n",
    "def save_mul(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['BinaryOp']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=2'])\n",
    "    return outputBlob\n",
    "\n",
    "def save_add(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['BinaryOp']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=0'])\n",
    "    return outputBlob\n",
    "\n",
    "def save_split(name, inputBlob, outputBlob1, outputBlob2):\n",
    "    append_row_to_csv(['Split']+[name]+['1','2']+[inputBlob,outputBlob1,outputBlob2])\n",
    "    return outputBlob1, outputBlob2\n",
    "\n",
    "def save_concat(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['Concat']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=2'])\n",
    "    return outputBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save 3 types of conv2d unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conv_unit(unitType, indexTfLite, inputBlob, deconv, stage=''):\n",
    "    \n",
    "    def N(name):\n",
    "        return stage+'/'+name+'_'+str(indexTfLite)\n",
    "    \n",
    "    x = inputBlob\n",
    "    \n",
    "    if deconv:\n",
    "        x = save_interp(('interp'), x, N('interp'))\n",
    "        \n",
    "    x = save_conv(N('conv2d'),indexTfLite, x, N('conv2d'))\n",
    "    \n",
    "    if unitType == 'TanH':\n",
    "        x = save_tanh(N('tanh'),x,N('tanh'))\n",
    "    else:  \n",
    "        x,y = save_slice(N('slice'), x, N('conv2d')+'_A', N('conv2d')+'_B')\n",
    "\n",
    "        if unitType == 'Elu':\n",
    "            x = save_elu(N('elu'),x,N('elu'))\n",
    "        if unitType == 'Relu':\n",
    "            x = save_relu(N('relu'),x,N('relu'))\n",
    "\n",
    "        y = save_sigmoid(N('sigmoid'),y,N('sigmoid'))\n",
    "        x = save_mul(N('mul'),x,y,N('mul'))   \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stage1/mul_13'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_conv_unit('Elu',13,'concat',True,stage='stage1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\x80?'\n"
     ]
    }
   ],
   "source": [
    "init_bin()  # it can flash bin file\n",
    "stage1 = [13,20,25,30,35, 40,45,50,55,60, 65,70,76,81,87, 92,97]\n",
    "index = 1\n",
    "x = 'concat'\n",
    "for i in stage1:\n",
    "    unitType = 'TanH' if index == 17 else 'Elu'\n",
    "    deconv = True if index in [13,15] else False\n",
    "    x = save_conv_unit(unitType,i,x,deconv,'stage1')\n",
    "    index += 1\n",
    "x = save_mul('stage1/output_mask2_mul', 'mask_2', x, 'stage1/output_mask2_mul')\n",
    "x = save_add('stage1/output_bi_add', 'sub_2', x, 'stage1/output_bi_add')\n",
    "x,y = save_split('stage2',x,'stage2_A','stage2_B')\n",
    "\n",
    "stage2_A = [101,111,121,131,141, 151,162,173,181,186]\n",
    "index = 1\n",
    "for i in stage2_A:\n",
    "    x = save_conv_unit('Elu',i,x,False,'stage2_A')\n",
    "    index += 1\n",
    "    \n",
    "stage2_B = [102,112,122,132,142, 152,161,170]\n",
    "index = 1\n",
    "for i in stage2_B:\n",
    "    unitType = 'Relu' if index == 6 else 'Elu'\n",
    "    y = save_conv_unit(unitType,i,y,False,'stage2_B')\n",
    "    index += 1\n",
    "    \n",
    "x = save_concat('concat2',x,y,'concat2')\n",
    "\n",
    "stage2_C = [192,197,203,208,214, 219,224]\n",
    "index = 1\n",
    "for i in stage2_C:\n",
    "    unitType = 'TanH' if index == 7 else 'Elu'\n",
    "    deconv = True if index in [3,5] else False\n",
    "    x = save_conv_unit(unitType,i,x,deconv,'stage2_C')\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_csv_to_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
