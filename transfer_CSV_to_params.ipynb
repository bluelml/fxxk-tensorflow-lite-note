{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import struct\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trans .csv to .param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_csv_to_param():\n",
    "    with open(netName+'.param','w') as p: \n",
    "        with open(netName+'.csv','r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "\n",
    "            blobs = []\n",
    "            outputcontent = ''\n",
    "            row_index = 0\n",
    "            for row in f_csv:   ## read rows in csv\n",
    "                # normal lines <layertype   layername   inputNum outputNum inputBlob outputBlob params>\n",
    "                col_index = 0\n",
    "                for col in row:\n",
    "                    if col_index == 0:                # layertype\n",
    "                        outputcontent += '%-16s ' % (col)\n",
    "                    elif col_index == 1:              # layername\n",
    "                        outputcontent += '%-32s ' % (col)\n",
    "                    elif col_index == 2:              # inputNum\n",
    "                        inputBlobNum = int(col)\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    elif col_index == 3:              # outputNum\n",
    "                        outputBlobNum = int(col)\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    elif col_index > 3 and col_index <= 3+inputBlobNum+outputBlobNum:  # inputBlob outputBlob\n",
    "                        blobs.append(col)\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    else:                             # params\n",
    "                        outputcontent += ' %s' % (col)\n",
    "                    col_index += 1\n",
    "                outputcontent += '\\n'\n",
    "                row_index += 1  ## end of read rows in csv\n",
    "            outputcontent = '7767517\\n'+'%s '%(row_index)+'%s\\n'%(len(list(set(blobs))))+outputcontent\n",
    "            p.write(outputcontent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process conv unit from json to csv\n",
    "# save json buffer data to bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = \"/home/gx/myproj/flatbuffers/im14_without_q_att.json\"\n",
    "with open(jsonpath,'r') as f_json:\n",
    "    model = json.load(f_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append new row to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row_to_csv(appendList):\n",
    "    with open(netName +'.csv','a', newline = \"\") as f:\n",
    "        csv_writer = csv.writer(f, dialect = \"excel\")\n",
    "        csv_writer.writerow(appendList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save TF-buffer data to NCNN-bin file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM o-h-w-i(tflite) TO o-i-h-w(ncnn)\n",
    "def fix_weight_order(a,shape):\n",
    "    temp = np.array(a).reshape(shape+(4,))\n",
    "    print(temp.transpose(0,3,1,2,4).shape)\n",
    "    return temp.transpose(0,3,1,2,4).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imagedata(npa,filename):\n",
    "    import os\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except:\n",
    "        pass\n",
    "    with open(filename,'w+') as f:\n",
    "        temp = npa.flatten()\n",
    "\n",
    "        print(npa.shape)\n",
    "        index = 1\n",
    "        sum = 0\n",
    "        for i in temp.tolist():\n",
    "            f.write(str(i)[0:8])\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 5, 5, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "a = [i for i in range(24000)]\n",
    "b = fix_weight_order(a,(48,5,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weight & bias data from tflite-json file to ncnn-bin file\n",
    "def save_data_to_bin(bufferIndex, shape=(), savefilter=True, append=True):\n",
    "    bufferData = model['buffers'][bufferIndex]['data']\n",
    "    flag = 'ab' if append else 'wb'\n",
    "    with open(netName+'.bin',flag) as f:\n",
    "        if savefilter:\n",
    "            i = 0x00000000   # flag-structure: weight data need to save as float type\n",
    "            f.write(struct.pack('<I',i))\n",
    "            bufferData = fix_weight_order(bufferData,shape)\n",
    "        for i in bufferData: # sava bufferdata, no need flag-structure\n",
    "            f.write(struct.pack('B',i))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save several type of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 5, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "op = model['subgraphs'][0]['operators']\n",
    "tensor = model['subgraphs'][0]['tensors']\n",
    "indexTfLite = 13\n",
    "filterTensor = op[indexTfLite]['inputs'][1]\n",
    "print(tuple(tensor[filterTensor]['shape']))\n",
    "\n",
    "fliterShape = tuple(tensor[filterTensor]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[filterTensor]['buffer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bufferData = model['buffers'][375]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = b''\n",
    "for i in bufferData:\n",
    "    res+=(struct.pack('B',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conv(name, indexTfLite, inputBlob, outputBlob):\n",
    "    \n",
    "    op = model['subgraphs'][0]['operators']\n",
    "    tensor = model['subgraphs'][0]['tensors']\n",
    "    \n",
    "    filterTensor = op[indexTfLite]['inputs'][1]\n",
    "    biasTensor = op[indexTfLite]['inputs'][2]\n",
    "\n",
    "    if 'dilation_w_factor' in op[indexTfLite]['builtin_options'].keys():\n",
    "        dilation_w_factor = op[indexTfLite]['builtin_options']['dilation_w_factor']\n",
    "    else:\n",
    "        dilation_w_factor = '1'\n",
    "        \n",
    "    if 'stride_w' in op[indexTfLite]['builtin_options'].keys():\n",
    "        stride_w = op[indexTfLite]['builtin_options']['stride_w']\n",
    "    else:\n",
    "        stride_w = '1'\n",
    "\n",
    "    fliterShape = tuple(tensor[filterTensor]['shape'])\n",
    "    \n",
    "    param = ['0=' + str(fliterShape[0]),                    # num_output\n",
    "             '1=' + str(fliterShape[1]),                    # kernel_w   （kernel_h default）\n",
    "             '2=' + str(dilation_w_factor),                 # rate\n",
    "             '3=' + str(stride_w),                          # stride\n",
    "             '4=-233',                                      # same\n",
    "             '5=1',                                         # has bias\n",
    "             '6=' + str(reduce(lambda x,y:x*y,fliterShape)) # weight\n",
    "            ]\n",
    "    \n",
    "    append_row_to_csv(['Convolution']+[name]+['1','1']+[inputBlob,name]+param)\n",
    "    save_data_to_bin(tensor[filterTensor]['buffer'],fliterShape,savefilter=True)  # save filter's buffer (weight)\n",
    "    save_data_to_bin(tensor[biasTensor]['buffer'],savefilter=False)   # save bias's   buffer \n",
    "    return outputBlob\n",
    "\n",
    "def save_slice(name, inputBlob, outputBlob1, outputBlob2):\n",
    "    append_row_to_csv(['Slice']+[name]+['1','2']+[inputBlob,outputBlob1,outputBlob2]+['-23300=2,-233,-233','1=0'])\n",
    "    return outputBlob1, outputBlob2\n",
    "\n",
    "def save_interp(name, inputBlob, outputBlob):                         # ResizeNearestNeighbor 2*\n",
    "    append_row_to_csv(['Interp']+[name]+['1','1']+[inputBlob,outputBlob]+['0=1','1=2.0','2=2.0']) \n",
    "    return outputBlob\n",
    "\n",
    "def save_elu(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['ELU']+[name]+['1','1']+[inputBlob,outputBlob]+['0=1.0'])\n",
    "    return outputBlob\n",
    "    \n",
    "def save_relu(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['ReLU']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "    \n",
    "def save_tanh(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['TanH']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "    \n",
    "def save_sigmoid(name, inputBlob, outputBlob):\n",
    "    append_row_to_csv(['Sigmoid']+[name]+['1','1']+[inputBlob,outputBlob])\n",
    "    return outputBlob\n",
    "\n",
    "def save_mul(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['BinaryOp']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=2'])\n",
    "    return outputBlob\n",
    "\n",
    "def save_add(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['BinaryOp']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=0'])\n",
    "    return outputBlob\n",
    "\n",
    "def save_sub(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['BinaryOp']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=1'])\n",
    "    return outputBlob\n",
    "\n",
    "def save_split(name, inputBlob, outputBlob1, outputBlob2):\n",
    "    append_row_to_csv(['Split']+[name]+['1','2']+[inputBlob,outputBlob1,outputBlob2])\n",
    "    return outputBlob1, outputBlob2\n",
    "\n",
    "def save_concat(name, inputBlob1, inputBlob2, outputBlob):\n",
    "    append_row_to_csv(['Concat']+[name]+['2','1']+[inputBlob1,inputBlob2,outputBlob]+['0=0']) # 0 dim concat 1 h 2 w\n",
    "    return outputBlob\n",
    "\n",
    "def save_input(name, d0, d1, d2):\n",
    "    append_row_to_csv(['Input']+[name]+['0','1']+[name]+['0='+str(d0)]+['1='+str(d1)]+['2='+str(d2)])\n",
    "    return name\n",
    "\n",
    "def save_memorydata(name, d0, d1, d2):\n",
    "    append_row_to_csv(['MemoryData']+[name]+['0','1']+[name]+['0='+str(d0)]+['1='+str(d1)]+['2='+str(d2)])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save 3 types of conv2d unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conv_unit(unitType, indexTfLite, inputBlob, deconv, stage=''):\n",
    "    \n",
    "    def N(name):\n",
    "        return stage+'/'+name+'_'+str(indexTfLite)\n",
    "    \n",
    "    x = inputBlob\n",
    "    \n",
    "    if deconv:\n",
    "        x = save_interp(('interp'), x, N('interp'))\n",
    "        \n",
    "    x = save_conv(N('conv2d'),indexTfLite, x, N('conv2d'))\n",
    "    \n",
    "    if unitType == 'TanH':\n",
    "        x = save_tanh(N('tanh'),x,N('tanh'))\n",
    "    else:  \n",
    "        x,y = save_slice(N('slice'), x, N('conv2d')+'_A', N('conv2d')+'_B')\n",
    "\n",
    "        if unitType == 'ELU':\n",
    "            x = save_elu(N('elu'),x,N('elu'))\n",
    "        if unitType == 'ReLU':\n",
    "            x = save_relu(N('relu'),x,N('relu'))\n",
    "\n",
    "        y = save_sigmoid(N('sigmoid'),y,N('sigmoid'))\n",
    "        x = save_mul(N('mul'),x,y,N('mul'))   \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net():\n",
    "    \n",
    "    import os \n",
    "    try:\n",
    "        os.remove(netName+'.csv')\n",
    "        os.remove(netName+'.bin')\n",
    "    except:\n",
    "        pass\n",
    "    #########   save memorydata ########\n",
    "    a = [1]\n",
    "    with open(netName+'.bin','wb') as f:\n",
    "        for i in a:\n",
    "            print(struct.pack('<f',i))\n",
    "            f.write(struct.pack('<f',i))\n",
    "    ####################################        \n",
    "\n",
    "    \n",
    "    x = save_input('data',512,680,3)\n",
    "    y = save_input('mask',512,680,3)\n",
    "    x1,x2 = save_split('b_i/split',x,'b_i_1','b_i_2')\n",
    "    y1,y2 = save_split('mask/split',y,'mask_1','mask_2')\n",
    "    y11,y12 = save_split('mask/split_1',y1,'mask_1_1','mask_1_2')\n",
    "    m = save_memorydata('one',1,0,0)\n",
    "    y11 = save_sub('sub', m, y11, 'sub')\n",
    "    y111,y112 = save_split('one_sub_mask/split',y11,'sub_1','sub_2')\n",
    "    i = save_input('inpaint',512,680,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'netName' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ac7f48e88dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minit_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# also flash param & bin file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m76\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m81\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inpaint'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstage1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b6309c70d8a1>\u001b[0m in \u001b[0;36minit_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#########   save memorydata ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<f'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'netName' is not defined"
     ]
    }
   ],
   "source": [
    "init_net()  # also flash param & bin file \n",
    "stage1 = [13,20,25,30,35, 40,45,50,55,60, 65,70,76,81,87, 92,97]\n",
    "index = 1\n",
    "x = 'inpaint'\n",
    "for i in stage1:\n",
    "    unitType = 'TanH' if index == 17 else 'ELU'\n",
    "    deconv = True if index in [13,15] else False\n",
    "    x = save_conv_unit(unitType,i,x,deconv,'stage1')\n",
    "    index += 1\n",
    "    \n",
    "x = save_mul('stage1/output_mask2_mul', 'mask_2', x, 'stage1/output_mask2_mul')\n",
    "bm = save_mul('bi_submask', 'sub_2', 'b_i_2', 'bi_submask')\n",
    "x = save_add('stage1/output_bi_add', bm, x, 'stage1/output_bi_add')\n",
    "x,y = save_split('stage2',x,'stage2_A','stage2_B')\n",
    "\n",
    "stage2_A = [101,111,121,131,141, 151,162,173,181,186]\n",
    "index = 1\n",
    "for i in stage2_A:\n",
    "    x = save_conv_unit('ELU',i,x,False,'stage2_A')\n",
    "    index += 1\n",
    "    \n",
    "stage2_B = [102,112,122,132,142, 152,161,170]\n",
    "index = 1\n",
    "for i in stage2_B:\n",
    "    unitType = 'ReLU' if index == 6 else 'ELU'\n",
    "    y = save_conv_unit(unitType,i,y,False,'stage2_B')\n",
    "    index += 1\n",
    "    \n",
    "x = save_concat('concat2',x,y,'concat2')\n",
    "\n",
    "stage2_C = [192,197,203,208,214, 219,224]\n",
    "index = 1\n",
    "for i in stage2_C:\n",
    "    unitType = 'TanH' if index == 7 else 'ELU'\n",
    "    deconv = True if index in [3,5] else False\n",
    "    x = save_conv_unit(unitType,i,x,deconv,'stage2_C')\n",
    "    index += 1\n",
    "    \n",
    "\n",
    "pm1 = save_mul('mul', 'b_i_1', 'sub_1', 'mul')\n",
    "pm2 = save_mul('mul_1', 'mask_1_2', x, 'mul_1')\n",
    "x = save_add('add', pm1, pm2, 'add')\n",
    "\n",
    "trans_csv_to_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "netName = 'mynet_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_net()\n",
    "post_net('b_i_2')\n",
    "trans_csv_to_param()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
